# Latent Dirichlet Allocation

- 각 문서의 주제 분포와 각 주제 내의 단어 분포를 추정

- 문서1 : 규찬이는 딥페이크와 객체 탐지를 공부해요
- 문서2 : 민화는 재밌는 자연어처리가 좋아요
- 문서3 : 형훈이는 스릴있고 재밌는 자연어처리에 객체 탐지까지 공부해요

- 위의 문서에서 2개의 주제를 찾는다고 가정
- 전처리 과정은 진행했다고 가정

## <각 문서의 주제 분포>
- 문서 1 : CV 100%
- 문서 2 : NLP 100%
- 문서 3 : CV 40%, NLP 60%

## <각 주제 단어 분포>
- CV : 딥페이크 20%, 객체 탐지 40%, 공부해요 40%
- NLP : 재밌는 33%, 자연어처리 33%, 좋아요 16%, 스릴있는 16%
# LDA 가정

- BoW DTM 또는 TF-IDF 행렬를 입력으로
- 순서는 상관하지 않음

1. 문서에 사용할 단어의 개수 N을 지정
2. 문서에 사용할 주제의 혼합을 확률 분포에 기반하여 결정
3. 문서에 사용할 각 단어를 아래와 같이 정함
3-1). 60% 확률로 자연어 처리에 대한 주제를 선택하고, 40% 확률로 CV 주제를 선택할 수 있음
3-2). 선택한 주제 T에서 단어의 출현 확률 분포에 기반해 문서에 사용할 단어를 고름
- ex) 자연어치리 주제를 선택하였다면, 33% 확률로 자연어처리 라는 단어를 선택할 수 있음

# LDA 수행

## 1. 사용자는 주제의 개수를 알려줌
- k개의 주제 수를 입력받으면, k개의 주제가 M개의 전체 문서에 걸쳐 분포되어 있다고 가정

## 2. 모든 단어를 k개 중 하나의 주제에 할당
- 모든 문서의 모든 단어에 대해서 k개 중 하나의 주제를 무작위로 할당
- 이 작업이 끝나면 모든 문서는 주제를 가지며, 주제는 단어 분포를 가지는 상태

## 3. 어떤 문서의 각 단어 w는 자신이 잘못된 주제에 할당되어 있다고 가정(다른 단어들은 올바르게 되었다고 가정)
- P(주제 t | 문서 d) : 문서 d의 단어들 중 주제 t에 해당하는 단어의 비율
- P(단어 w | 주제 t) : 각 주제 t에서 해당 단어 w의 분포
- 이 과정을 모든 단어에 대하여 반복

<img width="279" alt="캡처" src="https://user-images.githubusercontent.com/80622859/201518693-d6c11792-403d-4826-8ce7-5645ba7ffacb.PNG">

- 초기 상태(무작위로 주제를 배정받은 후의 상태)

### 1. 문서 1의 단어들이 어떤 주제에 해당하는지
- 문서 1에서 주제 A와 주제 B의 개수는 각각 2개, 2개
- apple은 50% 확률로 A 또는 B에 배정받을 수 있음

### 2. 단어 apple이 전체 문서에서 어떤 주제에 할당되어져 있는지
- 100% 확률로 B
- apple은 B에 할당될 가능성이 높음

- 1번과 2번에서 나온 값들을 곱해서 최종적인 확률 계산
