# 시간펼침 역전파 학습법

## 순차 데이터셋의 구조

1. 다중 입력, 단일 출력
2. 다중 입력, 다중 출력
3. 단일 입력, 다중 출력

- 입력 또는 출력 중 하나라도 순차 데이터라면, 순환 신경망을 이용해 학습할 수 있음

## 순환신경망의 순방향 추론

![image](https://user-images.githubusercontent.com/80622859/222883961-de952540-6cdd-4ae8-8ec6-780d9bfe955b.png)

- 입력을 순차적으로 입력하여 마지막 입력 시의 출력을 사용

## 시간 펼침 역전파(Back Propagation Through Time, BPTT)

![image](https://user-images.githubusercontent.com/80622859/222884038-6428a57d-dcc0-436a-8a88-ef9c88929896.png)

- 역전파와 동일하게, 시간적으로 펼쳐 둔 상태에서 역전파
- 시간적으로 펼쳐진 변수들은 동일한 변수
- 시간적으로 펼칠 때 역전파를 위한 추가적인 memory 필요
- 시간적으로 펼침 + Batch로 펼침
- 순차 데이터의 길이(L)가 매우 클 경우, 시간 펼침이 늘어나면서 필요 memory가 L배 증가
- Batch개의 sample을 동시에 계산하므로 얕은 신경망에 비해 큰 memory 필요

### 단일 입력, 단일 출력

- 입력이 한 번 들어온 이후 여러 개의 출력을 냄
- 실제로는 입력을 넣고 계산해야 하기 때문에 All-zero 입력을 넣어줌. 또는 미리 정해놓은 값 입력

### 다중 입력, 다중 출력

- 입력과 출력이 매 time-step 마다 이루어지는 경우
- 동영상의 frame 별 분류
- 모든 입력을 받은 후에 출력을 내는 경우(번역기, chatbot etc)
- Shifted method
- Seq2Seq

## Truncated BPTT

![image](https://user-images.githubusercontent.com/80622859/222946837-5dee9492-ae89-4693-990f-cae8100e6e1c.png)

- 다중 입력, 다중 출력일 경우 사용
- 순차 데이터의 길이를 일정한 T 길이로 잘라서 batch를 나누듯이 한 번에 계산하는 크기를 줄임
- 길이 L의 입력을 길이 T로 쪼개어 순서대로 학습
- 한 번에 역전파하는 길이가 제한되므로 memory 사용이 줄어듦

![image](https://user-images.githubusercontent.com/80622859/222946931-7f5a2d7e-330c-4211-8492-5b9724b5749e.png)

- 길이 T로 쪼개진 truncation 사이에서는 기울기 역전파가 이루어지지 않음
- Time step이 T 이상 떨어진 입-출력 관계는 학습되지 않음

