# 심화 순환 신경망

## 기울기 소실 문제

![image](https://user-images.githubusercontent.com/80622859/222882508-a697fe0f-b721-433c-a8eb-992514568f6b.png)

- 어떤 입력의 정보가 사용되는 시점의 차이가 많이 날 경우, 학습 능력이 저하

## Vanilla RNN

![image](https://user-images.githubusercontent.com/80622859/222882542-d8e6fb81-37ba-4eed-a8c0-681f2f07d13c.png)

- tanh activation function

## LSTM(Long Short-Term Memory)

![image](https://user-images.githubusercontent.com/80622859/222882607-3ad630f9-7acf-4e55-a72f-a7244c9ba331.png)

- Vanilla RNN을 개선한 구조
- 기억할 것은 오래 기억하고, 잊을 것은 빨리 잊어버리자

### Cell state

![image](https://user-images.githubusercontent.com/80622859/222884556-9d4e1fb5-fc54-4d69-9129-e15a7dcfa69f.png)

- 기억을 오랫동안 유지할 수 있는 구조, 새로운 특징을 덧셈으로 받는 구조(Residual Network)
- RNN과 달리, cell state가 있어서 기억에 관한 부분을 전담
- 기억을 총괄하는 memory 역할
- 여러 차원으로 되어 있어, 각 차원은 특정 정보를 기억
- Hadamard 연산자(element-wise)의 특성으로 인해, 특징 별로 기억하고, 잊고, 새로이 정보를 받을 수 있음

### hidden state

- 계층의 출력/다음 time step으로 넘기는 정보
- Cell state에 tanh activation을 적용한 후, output gate를 선별하여 출력
- tanh를 사용하는 이유는 출력 값의 범위가 -1~1로 제한두기 위함 


### Forget gate

![image](https://user-images.githubusercontent.com/80622859/222882929-1b69e47e-0ea4-4e52-8d44-cd7fc51f7b24.png)

- Sigomid 활성 함수로, 0~1의 출력 값을 가짐
- Cell state에 이를 곱해 주어서 얼만큼 잊을지를 결정
- 특징은 여러 차원으로 되어 있으므로, 특징별로 기억할지 말지를 결정할 수 있음

### Input gate

![image](https://user-images.githubusercontent.com/80622859/222883246-9d48fef3-9c68-4480-b8ae-b5135dbdbc8c.png)

- Sigmoid 활성 함수로, 0~1의 출력 값을 가짐
- 새롭게 추출한 특징을 얼만큼 사용할 지 결정
- 새로운 입력을 받고자 하는 정도를 나타냄
- 특징은 여러 차원으로 되어 있으므로, 특징별로 받아들일지 말지를 결

### Output Gate

![image](https://user-images.githubusercontent.com/80622859/222883398-3216a33f-ed44-4b5a-a7c8-de5439dcace1.png)

- Sigmoid 활성 함수로, 0~1의 출력 값을 가짐
- Cell로부터 출력을 얼마나 내보낼지 결정하는 역할
- Cell state 중 어떤 특징을 출력할지 결정 
- 경사 폭발 문제를 막기 위해 tanh 함수 사용

## GRU(Gated Recurrent Unit)

![image](https://user-images.githubusercontent.com/80622859/222883485-6a1cd7d6-0192-451c-a01d-67a7eadc0609.png)

![image](https://user-images.githubusercontent.com/80622859/222884695-b9ccc81a-3ddc-4f3d-8272-0801c05fb45d.png)

- Cell state가 없고, hidden state만 존재
- Forget gate와 input gate 결합
- Reset gate 추가

### Forget gate & Input gate

- LSTM과 동일한 forget gate를 사용
- LSTM의 forget gate와 output gate를 겸함
- forget gate를 1에서 빼서 input gate로 사용

### Reset gate

- Sigmoid 활성 함수로, 0~1의 값
- 이전 은닉 상태를 얼마나 사용할지 정하는 역할
- 0에 가까운 값이 되면 reset 됨.(Ex. 새 문장의 시작)
- Reset된 특징은 현재 time step부터 전결합계층 입력에서 제외

### Hidden state

- Reset gate, forget gate를 모두 적용하여 은닉 상태를 계산
- LSTM의 cell state와 은닉 상태 역할을 모두 겸함 

