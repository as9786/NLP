# 심화 순환 신경망

## 기울기 소실 문제

![image](https://user-images.githubusercontent.com/80622859/222882508-a697fe0f-b721-433c-a8eb-992514568f6b.png)

- 어떤 입력의 정보가 사용되는 시점의 차이가 많이 날 경우, 학습 능력이 저하

## Vanilla RNN

![image](https://user-images.githubusercontent.com/80622859/222882542-d8e6fb81-37ba-4eed-a8c0-681f2f07d13c.png)

- tanh activation function

## LSTM(Long Short-Term Memory)

![image](https://user-images.githubusercontent.com/80622859/222882607-3ad630f9-7acf-4e55-a72f-a7244c9ba331.png)

- Vanilla RNN을 개선한 구조
- 기억할 것은 오래 기억하고, 잊을 것은 빨리 잊어버리자

### Cell state, hidden state

- Cell state : 기억을 오랫동안 유지할 수 있는 구조, 새로운 특징을 덧셈으로 받는 구조(Residual Network)
- Hidden state : 계층의 출력/다음 time step으로 넘기는 정보
- RNN과 달리, cell state가 있어서 기억에 관한 부분을 전
