# Machine Translation and Encoder-Decoder Models

- 현재 형태의 기계 번역은 매우 실용적인 작업에 초점을 맞춤
- 인간 번역가를 도움
- 통신에 도움
- 순환신경망 또는 transformer로 구현할 수 있는 구조인 seq2seq이라 불리는 encoder-decoder 구조의 신경망
- 입력 단어 또는 token sequence에서 개별 단어의 직접 매핑이 아닌 tag sequence로 매핑해야 함
- 언어의 단어가 숫자나 순서에서 소스 언어의 단어와 반드시 일치하지 않음. ex) 일본 -> 영어
- 문장의 요소들이 언어마다 매우 다른 위치에 있음
- 대소문자 유무
- seq2seq은 기계 번역만을 위한것이 아니라 두 시퀀스 간의 복잡한 매핑이 관련된 다른 많은 작업을 위한 최신 기술. ex)요약, 대화, 의미 구문 분석 등

## 10.1 Language Divergences and Typology

### 10.1.1 Word Order Typology

- 언어마다 어순이 다름

![image](https://user-images.githubusercontent.com/80622859/204005853-514d9989-e843-4e2e-86a0-b99f6b2cd55f.png)

### 10.1.2 Lexical Divergences

- 번역은 문맥에 따라 적절한 단어가 달라질 수 있음
- 한 언어가 다른 언어보다 단어 선택에 더 많은 문법적 제약을 가할 수 있음
- Many-to-many mapping

### 10.1.3 Morphological Typology

- 단일 단어가 영어 전체 문장에 해당하는 매우 많은 형태소를 가질 수 있는 다합성 언어
- 형태소가 분할 가능할 정도로 상대적으로 깨끗한경계를 가진 융합 언어

### 10.1.4 Referential density

- 지시어 
- ex) 일본어와 중국어는 스페인어보다 훨씬 더 많이 생략하는 경향
- Cold language : 추론적인 작업을 더 많이 해야 하는 언어
- Hot language : 더 명확하고 듣는 사람이 더 쉽게 들을 수 있는 언어

## 10.2 The Encoder-Decoder Model

- 임의의 길이의 출력 시퀀스를 생성할 수 있는 모형
- 입력 시퀀스를 취하고 종종 context라고 불리는 맥락화된 표현을 만듦
- Context는 decode로 전달

![image](https://user-images.githubusercontent.com/80622859/204006577-913f49f1-70cf-459a-9e88-148a2998aa24.png)

## Encoder-Decoder with RNNs

![image](https://user-images.githubusercontent.com/80622859/204006825-b1afddc0-cd02-43ec-968f-b268720dfc6b.png)

- Encoder의 전체 목적은 입력의 상황에 맞는 표현을 생성
- 이러한 context는 enocoder의 마지막 은닉 상태에서 구현
- Decoder는 시퀀스 종료 마커가 생성될 때까지 한 번에 요소를 자동으로 생성함
- 각 은닉 상태는 이전 은닉 상태와 이전 상태에서 생성된 출력에 따라 조절

![image](https://user-images.githubusercontent.com/80622859/204007114-b3c7f5f6-7db3-492a-97de-a5c212b8a48a.png)

- 단점 : context가 시간이 지날수록 영향력이 감소함
- 위의 단점을 해결하기 위해서 각 단계에서 context vector c를 사용할 수 있게 함

![image](https://user-images.githubusercontent.com/80622859/204007195-c416633d-b4db-40aa-91e7-ee8e1d01848e.png)

- 마지막으로 softmax를 통해서 각 시간 단계에서 가장 가능성이 높은 출력을 계산

### 10.3.1 Training the Encoder-Decoder Model

- End-to-end
- 문장 세트와 그 번역으로 구성

![image](https://user-images.githubusercontent.com/80622859/204007408-409aa33c-da56-49af-aef8-0e58be3f6017.png)

- 교사 강제를 통해 학습

## 10.4 Attention

- Decoder가 마지막 은닉 상태뿐만 아니라 encoder의 숨겨진 모든 은닉 상태로부터 정보를 얻을 수 있도록 하는 방법
- 모든 encoder의 은닉 상태의 가중 합계를 취하여 단일 고정 길이 vector c를 만드는ㄱ ㅓㅅ
- Decoder가 현재 생성하고 있는 token과 관련된 source text의 특정 부분에 초점을 맞춤
- Attention은 static context vector를 decoder의 각 token에 대해 다른 encoder 은닉 상태에서 동적으로 파생된 vector 대체
- 이 context vector는 각 디코딩 단계 i와 함께 새로 생성되고 모든 인코더의 은닉 상태를 고려

![image](https://user-images.githubusercontent.com/80622859/204007872-e5c15bad-fedc-40db-b943-7422091eb8b4.png)

- $c_i$를 계산하는 첫 번째 단계는 각 encoder state에 얼마나 초점을 맞출 것인지, 각 encoder state가 $h^d_i$에서 얻은 decoder 상태와 얼마나 관련이 있는지 계산 
- Dot production attention score : 단순한 유사성을 계산
![image](https://user-images.githubusercontent.com/80622859/204008136-94cd2723-1254-4e85-88e8-626102f4736e.png)

![image](https://user-images.githubusercontent.com/80622859/204008156-6c509a07-bd14-4821-a29b-e9b938dfac9e.png)

